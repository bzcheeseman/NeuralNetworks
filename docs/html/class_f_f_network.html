<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NeuralNetworks: FFNetwork Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NeuralNetworks
   &#160;<span id="projectnumber">0.1</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-types">Private Types</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="#friends">Friends</a> &#124;
<a href="class_f_f_network-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">FFNetwork Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Holds a basic Feed Forward fully connected neural network.  
 <a href="class_f_f_network.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_f_f_network_8hpp_source.html">src/FFNetwork.cpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:acad78fd08b3067730bf313c481927819"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#acad78fd08b3067730bf313c481927819">FFNetwork</a> (std::vector&lt; unsigned &gt; <a class="el" href="class_f_f_network.html#a280876ec9dc93c5ecb08d7827a4fb83d">topology</a>, std::vector&lt; unsigned &gt; <a class="el" href="class_f_f_network.html#a975cfb66d3fefd85f96e7715e84a0bf8">dropout</a>, double <a class="el" href="class_f_f_network.html#a8634f492cf6aa8c32c7f69eef0daa70e">eta</a>, double <a class="el" href="class_f_f_network.html#afdeb132a945d5df3825f57f069a6d8bd">lamda</a>, double <a class="el" href="class_f_f_network.html#a233e8637934edea0a7f94e5eac9d0b9b">gamma</a>, double <a class="el" href="class_f_f_network.html#a5a797019a331d0622cf4fd87df68a59a">epsilon</a>)</td></tr>
<tr class="memdesc:acad78fd08b3067730bf313c481927819"><td class="mdescLeft">&#160;</td><td class="mdescRight">The number of neurons in each layer.  <a href="#acad78fd08b3067730bf313c481927819">More...</a><br /></td></tr>
<tr class="separator:acad78fd08b3067730bf313c481927819"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95692ef8729df027377c76158c14a432"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a95692ef8729df027377c76158c14a432">~FFNetwork</a> ()</td></tr>
<tr class="separator:a95692ef8729df027377c76158c14a432"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93d2a75dbef514c8ebb6b1a610de7179"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a93d2a75dbef514c8ebb6b1a610de7179">setFunctions</a> (double(*<a class="el" href="class_f_f_network.html#a0fb8cf9b00f90297403a015038c2e551">phi</a>)(double), double(*<a class="el" href="class_f_f_network.html#a60ad55e5abbb5f3a2b017b6f38f17094">phiprime</a>)(double), double(*<a class="el" href="class_f_f_network.html#aded5a5a44a44bd4d2d5971c084912aaa">regularization</a>)(double), double(*<a class="el" href="class_f_f_network.html#a8cb7be8b47420fc834e5867dc4640414">dropout_fn</a>)(double), Eigen::VectorXd(*<a class="el" href="class_f_f_network.html#a3d7e7add4da8d6e2aa7c9fcd175c50c7">cost</a>)(Eigen::VectorXd, Eigen::VectorXd), Eigen::VectorXd(*<a class="el" href="class_f_f_network.html#a2d12a1923a6e3faf58df353d9789340c">costprime</a>)(Eigen::VectorXd, Eigen::VectorXd, Eigen::VectorXd))</td></tr>
<tr class="separator:a93d2a75dbef514c8ebb6b1a610de7179"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a755165acac080e33edd2c272a7a6d141"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a755165acac080e33edd2c272a7a6d141">setBackpropAlgorithm</a> (const char *algorithm)</td></tr>
<tr class="separator:a755165acac080e33edd2c272a7a6d141"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afeb2383ca3ef566ca44962cbae790f5c"><td class="memItemLeft" align="right" valign="top">Eigen::VectorXi&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#afeb2383ca3ef566ca44962cbae790f5c">operator()</a> (Eigen::VectorXd input)</td></tr>
<tr class="separator:afeb2383ca3ef566ca44962cbae790f5c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09d80dd2cf324173ebc3bbc1d668d924"><td class="memItemLeft" align="right" valign="top">Eigen::VectorXd&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a09d80dd2cf324173ebc3bbc1d668d924">feedForward</a> (Eigen::VectorXd input)</td></tr>
<tr class="separator:a09d80dd2cf324173ebc3bbc1d668d924"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aceecfdebef35a2a9602fb18b45a2875f"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#aceecfdebef35a2a9602fb18b45a2875f">SGD</a> (Eigen::VectorXd input, Eigen::VectorXd correct)</td></tr>
<tr class="separator:aceecfdebef35a2a9602fb18b45a2875f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9b6de9dbb01fd7f05ece2f3ddbed057"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#ab9b6de9dbb01fd7f05ece2f3ddbed057">MomentumSGD</a> (Eigen::VectorXd input, Eigen::VectorXd correct)</td></tr>
<tr class="separator:ab9b6de9dbb01fd7f05ece2f3ddbed057"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f92b83ccb06072793e7635e78eba811"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a2f92b83ccb06072793e7635e78eba811">Adadelta</a> (Eigen::VectorXd input, Eigen::VectorXd correct)</td></tr>
<tr class="separator:a2f92b83ccb06072793e7635e78eba811"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a27c95dd469cb1d172e390c901feca9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a9a27c95dd469cb1d172e390c901feca9">Train</a> (<a class="el" href="structdata_set.html">dataSet</a>&lt; double &gt; *training, <a class="el" href="structdata_set.html">dataSet</a>&lt; double &gt; *validation, double goal, long max_epochs, double min_gradient)</td></tr>
<tr class="separator:a9a27c95dd469cb1d172e390c901feca9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c4f9bbd8d5adbe3813d9b556dbdf312"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a4c4f9bbd8d5adbe3813d9b556dbdf312">Evaluate</a> (int rand_seed, <a class="el" href="structdata_set.html">dataSet</a>&lt; double &gt; *validation)</td></tr>
<tr class="separator:a4c4f9bbd8d5adbe3813d9b556dbdf312"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-types"></a>
Private Types</h2></td></tr>
<tr class="memitem:a496a71b6f9bffae659556a83bc6dc55a"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom">{ <a class="el" href="class_f_f_network.html#a496a71b6f9bffae659556a83bc6dc55aa2ee8ec6beaabebef1c2e5749c10e8335">StochGradDescent</a>, 
<a class="el" href="class_f_f_network.html#a496a71b6f9bffae659556a83bc6dc55aa133d2adfa58653ee514519d771b6feae">MOMSGD</a>, 
<a class="el" href="class_f_f_network.html#a496a71b6f9bffae659556a83bc6dc55aadb1baf221a6adcceb83b42f1c90a1668">ADADELTA</a>
 }<tr class="memdesc:a496a71b6f9bffae659556a83bc6dc55a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Chooses the backpropagation algorithm.  <a href="class_f_f_network.html#a496a71b6f9bffae659556a83bc6dc55a">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:a496a71b6f9bffae659556a83bc6dc55a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a280876ec9dc93c5ecb08d7827a4fb83d"><td class="memItemLeft" align="right" valign="top">std::vector&lt; unsigned &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a280876ec9dc93c5ecb08d7827a4fb83d">topology</a></td></tr>
<tr class="memdesc:a280876ec9dc93c5ecb08d7827a4fb83d"><td class="mdescLeft">&#160;</td><td class="mdescRight">The number of neurons in each layer.  <a href="#a280876ec9dc93c5ecb08d7827a4fb83d">More...</a><br /></td></tr>
<tr class="separator:a280876ec9dc93c5ecb08d7827a4fb83d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a975cfb66d3fefd85f96e7715e84a0bf8"><td class="memItemLeft" align="right" valign="top">std::vector&lt; unsigned &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a975cfb66d3fefd85f96e7715e84a0bf8">dropout</a></td></tr>
<tr class="memdesc:a975cfb66d3fefd85f96e7715e84a0bf8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Whether each layer is a dropout layer or not.  <a href="#a975cfb66d3fefd85f96e7715e84a0bf8">More...</a><br /></td></tr>
<tr class="separator:a975cfb66d3fefd85f96e7715e84a0bf8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8634f492cf6aa8c32c7f69eef0daa70e"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a8634f492cf6aa8c32c7f69eef0daa70e">eta</a></td></tr>
<tr class="memdesc:a8634f492cf6aa8c32c7f69eef0daa70e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Learning rate - used in SGD and MOMSGD only.  <a href="#a8634f492cf6aa8c32c7f69eef0daa70e">More...</a><br /></td></tr>
<tr class="separator:a8634f492cf6aa8c32c7f69eef0daa70e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afdeb132a945d5df3825f57f069a6d8bd"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#afdeb132a945d5df3825f57f069a6d8bd">lamda</a></td></tr>
<tr class="memdesc:afdeb132a945d5df3825f57f069a6d8bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Regularization rate - appears in a denominator so a value ~5e3 is recommended and speeds up training.  <a href="#afdeb132a945d5df3825f57f069a6d8bd">More...</a><br /></td></tr>
<tr class="separator:afdeb132a945d5df3825f57f069a6d8bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a233e8637934edea0a7f94e5eac9d0b9b"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a233e8637934edea0a7f94e5eac9d0b9b">gamma</a></td></tr>
<tr class="memdesc:a233e8637934edea0a7f94e5eac9d0b9b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Momentum parameter - a scaling parameter for MOMSGD and ADADELTA, around 0.9 is usually good.  <a href="#a233e8637934edea0a7f94e5eac9d0b9b">More...</a><br /></td></tr>
<tr class="separator:a233e8637934edea0a7f94e5eac9d0b9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a797019a331d0622cf4fd87df68a59a"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a5a797019a331d0622cf4fd87df68a59a">epsilon</a></td></tr>
<tr class="memdesc:a5a797019a331d0622cf4fd87df68a59a"><td class="mdescLeft">&#160;</td><td class="mdescRight">A small number used in ADADELTA for RMS calculation in the learning rate.  <a href="#a5a797019a331d0622cf4fd87df68a59a">More...</a><br /></td></tr>
<tr class="separator:a5a797019a331d0622cf4fd87df68a59a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac42c2c144ca007bfb21d0b1f38649412"><td class="memItemLeft" align="right" valign="top"><a class="el" href="struct_f_f_layer.html">FFLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#ac42c2c144ca007bfb21d0b1f38649412">layers</a></td></tr>
<tr class="memdesc:ac42c2c144ca007bfb21d0b1f38649412"><td class="mdescLeft">&#160;</td><td class="mdescRight">An array of the layers that make up the network.  <a href="#ac42c2c144ca007bfb21d0b1f38649412">More...</a><br /></td></tr>
<tr class="separator:ac42c2c144ca007bfb21d0b1f38649412"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fb8cf9b00f90297403a015038c2e551"><td class="memItemLeft" align="right" valign="top">double(*&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a0fb8cf9b00f90297403a015038c2e551">phi</a> )(double)</td></tr>
<tr class="memdesc:a0fb8cf9b00f90297403a015038c2e551"><td class="mdescLeft">&#160;</td><td class="mdescRight">The activation function.  <a href="#a0fb8cf9b00f90297403a015038c2e551">More...</a><br /></td></tr>
<tr class="separator:a0fb8cf9b00f90297403a015038c2e551"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a60ad55e5abbb5f3a2b017b6f38f17094"><td class="memItemLeft" align="right" valign="top">double(*&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a60ad55e5abbb5f3a2b017b6f38f17094">phiprime</a> )(double)</td></tr>
<tr class="memdesc:a60ad55e5abbb5f3a2b017b6f38f17094"><td class="mdescLeft">&#160;</td><td class="mdescRight">Derivative of the activation function.  <a href="#a60ad55e5abbb5f3a2b017b6f38f17094">More...</a><br /></td></tr>
<tr class="separator:a60ad55e5abbb5f3a2b017b6f38f17094"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d7e7add4da8d6e2aa7c9fcd175c50c7"><td class="memItemLeft" align="right" valign="top">Eigen::VectorXd(*&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a3d7e7add4da8d6e2aa7c9fcd175c50c7">cost</a> )(Eigen::VectorXd, Eigen::VectorXd)</td></tr>
<tr class="memdesc:a3d7e7add4da8d6e2aa7c9fcd175c50c7"><td class="mdescLeft">&#160;</td><td class="mdescRight">The cost function - returns a vector that corresponds to the cost per output neuron.  <a href="#a3d7e7add4da8d6e2aa7c9fcd175c50c7">More...</a><br /></td></tr>
<tr class="separator:a3d7e7add4da8d6e2aa7c9fcd175c50c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d12a1923a6e3faf58df353d9789340c"><td class="memItemLeft" align="right" valign="top">Eigen::VectorXd(*&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a2d12a1923a6e3faf58df353d9789340c">costprime</a> )(Eigen::VectorXd, Eigen::VectorXd, Eigen::VectorXd)</td></tr>
<tr class="memdesc:a2d12a1923a6e3faf58df353d9789340c"><td class="mdescLeft">&#160;</td><td class="mdescRight">The derivative of the cost function - returns a vector that again corresponds to output neurons.  <a href="#a2d12a1923a6e3faf58df353d9789340c">More...</a><br /></td></tr>
<tr class="separator:a2d12a1923a6e3faf58df353d9789340c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aded5a5a44a44bd4d2d5971c084912aaa"><td class="memItemLeft" align="right" valign="top">double(*&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#aded5a5a44a44bd4d2d5971c084912aaa">regularization</a> )(double)</td></tr>
<tr class="memdesc:aded5a5a44a44bd4d2d5971c084912aaa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Regularization function - Identity = L2, Sign = L1, Zero = None.  <a href="#aded5a5a44a44bd4d2d5971c084912aaa">More...</a><br /></td></tr>
<tr class="separator:aded5a5a44a44bd4d2d5971c084912aaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cb7be8b47420fc834e5867dc4640414"><td class="memItemLeft" align="right" valign="top">double(*&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a8cb7be8b47420fc834e5867dc4640414">dropout_fn</a> )(double)</td></tr>
<tr class="memdesc:a8cb7be8b47420fc834e5867dc4640414"><td class="mdescLeft">&#160;</td><td class="mdescRight">Dropout function - currenly only suppored in <a class="el" href="_dropoutand_regularization_8hpp.html">DropoutandRegularization.hpp</a> with Bernoulli.  <a href="#a8cb7be8b47420fc834e5867dc4640414">More...</a><br /></td></tr>
<tr class="separator:a8cb7be8b47420fc834e5867dc4640414"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef391b1c34f810e5f43faebf3ea1d9d9"><td class="memItemLeft" align="right" valign="top">enum FFNetwork:: { ... } &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#aef391b1c34f810e5f43faebf3ea1d9d9">backprop</a></td></tr>
<tr class="memdesc:aef391b1c34f810e5f43faebf3ea1d9d9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Chooses the backpropagation algorithm.  <a href="#aef391b1c34f810e5f43faebf3ea1d9d9">More...</a><br /></td></tr>
<tr class="separator:aef391b1c34f810e5f43faebf3ea1d9d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="friends"></a>
Friends</h2></td></tr>
<tr class="memitem:aff8be16d3ce26a44e8f057b460d5acfb"><td class="memItemLeft" align="right" valign="top">std::ostream &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#aff8be16d3ce26a44e8f057b460d5acfb">operator&lt;&lt;</a> (std::ostream &amp;out, <a class="el" href="class_f_f_network.html">FFNetwork</a> &amp;net)</td></tr>
<tr class="separator:aff8be16d3ce26a44e8f057b460d5acfb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abbe40a1420b004e1478d3d900880c346"><td class="memItemLeft" align="right" valign="top">std::ofstream &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#abbe40a1420b004e1478d3d900880c346">operator&lt;&lt;</a> (std::ofstream &amp;out, const <a class="el" href="class_f_f_network.html">FFNetwork</a> &amp;net)</td></tr>
<tr class="separator:abbe40a1420b004e1478d3d900880c346"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75f067d6b9a1d2ba91fa5a5e5b8a8a64"><td class="memItemLeft" align="right" valign="top">std::ifstream &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_f_f_network.html#a75f067d6b9a1d2ba91fa5a5e5b8a8a64">operator&gt;&gt;</a> (std::ifstream &amp;in, <a class="el" href="class_f_f_network.html">FFNetwork</a> *net)</td></tr>
<tr class="separator:a75f067d6b9a1d2ba91fa5a5e5b8a8a64"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Holds a basic Feed Forward fully connected neural network. </p>
<p>Contains a basic fully connected Feed Forward network. Holds training and backpropagation as well as the raw numbers needed to make it work. </p>
</div><h2 class="groupheader">Member Enumeration Documentation</h2>
<a id="a496a71b6f9bffae659556a83bc6dc55a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a496a71b6f9bffae659556a83bc6dc55a">&sect;&nbsp;</a></span>anonymous enum</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">anonymous enum</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Chooses the backpropagation algorithm. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a496a71b6f9bffae659556a83bc6dc55aa2ee8ec6beaabebef1c2e5749c10e8335"></a>StochGradDescent&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a496a71b6f9bffae659556a83bc6dc55aa133d2adfa58653ee514519d771b6feae"></a>MOMSGD&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a496a71b6f9bffae659556a83bc6dc55aadb1baf221a6adcceb83b42f1c90a1668"></a>ADADELTA&#160;</td><td class="fielddoc"></td></tr>
</table>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="acad78fd08b3067730bf313c481927819"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acad78fd08b3067730bf313c481927819">&sect;&nbsp;</a></span>FFNetwork()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FFNetwork::FFNetwork </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; unsigned &gt;&#160;</td>
          <td class="paramname"><em>topology</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; unsigned &gt;&#160;</td>
          <td class="paramname"><em>dropout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>eta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>lamda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>epsilon</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The number of neurons in each layer. </p>
<p>Constructor - sets various network parameters. Need to call setFunctions to set the activation, cost, regularization, and dropout functions.</p>
<p>Default initializes the backprop algorithm to ADADELTA - so be sure to call setBackpropAlgorithm if you want to change that.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">topology</td><td></td></tr>
    <tr><td class="paramname">dropout</td><td>Whether each layer is a dropout layer or not.</td></tr>
    <tr><td class="paramname">eta</td><td>Learning rate - used in SGD and MOMSGD only.</td></tr>
    <tr><td class="paramname">lamda</td><td>Regularization rate - appears in a denominator so a value ~5e3 is recommended and speeds up training.</td></tr>
    <tr><td class="paramname">gamma</td><td>Momentum parameter - a scaling parameter for MOMSGD and ADADELTA, around 0.9 is usually good.</td></tr>
    <tr><td class="paramname">epsilon</td><td>A small number used in ADADELTA for RMS calculation in the learning rate.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new neural network, mostly initialized! </dd></dl>

</div>
</div>
<a id="a95692ef8729df027377c76158c14a432"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a95692ef8729df027377c76158c14a432">&sect;&nbsp;</a></span>~FFNetwork()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FFNetwork::~FFNetwork </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Destructor - Deletes the pointer to the layers of the network - be sure to save first! </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a2f92b83ccb06072793e7635e78eba811"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f92b83ccb06072793e7635e78eba811">&sect;&nbsp;</a></span>Adadelta()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double FFNetwork::Adadelta </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>correct</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Implementation of the AdaDelta backpropagation algorithm from</p>
<p>ADADELTA: An Adaptive Learning Rate Method Zeiler, Matthew D. eprint arXiv:1212.5701 12/2012</p>
<p>Generally takes the fewest epochs to converge, though each epoch takes longer on average.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input to feed through the network </td></tr>
    <tr><td class="paramname">correct</td><td>The correct output that corresponds to the input we fed in. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The gradient of the surface at the beginning of that backprop step. </dd></dl>

</div>
</div>
<a id="a4c4f9bbd8d5adbe3813d9b556dbdf312"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c4f9bbd8d5adbe3813d9b556dbdf312">&sect;&nbsp;</a></span>Evaluate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double FFNetwork::Evaluate </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>rand_seed</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structdata_set.html">dataSet</a>&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>validation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Evaluates the neural network on a random input from the validation set. Takes in a random number and mods it with the length of the validation set to pick a testing dataset.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rand_seed</td><td>Random number used to choose which dataset to test on. </td></tr>
    <tr><td class="paramname">validation</td><td>Validation dataset - labeled examples we can use to test the network's performance. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Total cost from that feedforward iteration - applies the cost function to the network output. </dd></dl>

</div>
</div>
<a id="a09d80dd2cf324173ebc3bbc1d668d924"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a09d80dd2cf324173ebc3bbc1d668d924">&sect;&nbsp;</a></span>feedForward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::VectorXd FFNetwork::feedForward </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes a prediction based on the current network model. Feeds an input through the network and returns the output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input vector to the network </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Output of the network </dd></dl>

</div>
</div>
<a id="ab9b6de9dbb01fd7f05ece2f3ddbed057"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab9b6de9dbb01fd7f05ece2f3ddbed057">&sect;&nbsp;</a></span>MomentumSGD()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double FFNetwork::MomentumSGD </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>correct</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>An implementation of momentum-optimized stochastic gradient descent. There was probably a paper on this but I can't find it - will happily cite it but otherwise just got the general idea from Michael Nielsen's book and the equations for implementation from everywhere.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input to feed through the network </td></tr>
    <tr><td class="paramname">correct</td><td>The correct output that corresponds to the input we fed in. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The gradient of the surface at the beginning of that backprop step. </dd></dl>

</div>
</div>
<a id="afeb2383ca3ef566ca44962cbae790f5c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afeb2383ca3ef566ca44962cbae790f5c">&sect;&nbsp;</a></span>operator()()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::VectorXi FFNetwork::operator() </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Makes a prediction on the network. Uses the trained network and forward propagates one input to return one output. Hides the feedForward function in favor of an overloaded operator. Also truncates the network output which <a class="el" href="class_f_f_network.html#a09d80dd2cf324173ebc3bbc1d668d924">feedForward(Eigen::VectorXd)</a> does not do.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input vector to the network </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Truncated network output </dd></dl>

</div>
</div>
<a id="a755165acac080e33edd2c272a7a6d141"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a755165acac080e33edd2c272a7a6d141">&sect;&nbsp;</a></span>setBackpropAlgorithm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void FFNetwork::setBackpropAlgorithm </td>
          <td>(</td>
          <td class="paramtype">const char *&#160;</td>
          <td class="paramname"><em>algorithm</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets backprop algorithm. Uses strncmp to select the algorithm.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">algorithm</td><td>Possible inputs are "SGD", "MOMSGD", or "ADADELTA" </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a93d2a75dbef514c8ebb6b1a610de7179"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a93d2a75dbef514c8ebb6b1a610de7179">&sect;&nbsp;</a></span>setFunctions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void FFNetwork::setFunctions </td>
          <td>(</td>
          <td class="paramtype">double(*)(double)&#160;</td>
          <td class="paramname"><em>phi</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double(*)(double)&#160;</td>
          <td class="paramname"><em>phiprime</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double(*)(double)&#160;</td>
          <td class="paramname"><em>regularization</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double(*)(double)&#160;</td>
          <td class="paramname"><em>dropout_fn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Eigen::VectorXd(*)(Eigen::VectorXd, Eigen::VectorXd)&#160;</td>
          <td class="paramname"><em>cost</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Eigen::VectorXd(*)(Eigen::VectorXd, Eigen::VectorXd, Eigen::VectorXd)&#160;</td>
          <td class="paramname"><em>costprime</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sets the network functions!</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">phi</td><td>Activation function </td></tr>
    <tr><td class="paramname">phiprime</td><td>Derivative of the activation function </td></tr>
    <tr><td class="paramname">regularization</td><td>The regularization function - Identity is L2, Sign is L1, and Zero is none </td></tr>
    <tr><td class="paramname">dropout_fn</td><td>The dropout function to apply to each dropout layer (usually just bernoulli probability) </td></tr>
    <tr><td class="paramname">cost</td><td>The cost function </td></tr>
    <tr><td class="paramname">costprime</td><td>Derivative of the cost function </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aceecfdebef35a2a9602fb18b45a2875f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aceecfdebef35a2a9602fb18b45a2875f">&sect;&nbsp;</a></span>SGD()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double FFNetwork::SGD </td>
          <td>(</td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Eigen::VectorXd&#160;</td>
          <td class="paramname"><em>correct</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Standard Stochastic Gradient Descent - quite basic but it gets the job done.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input to feed through the network </td></tr>
    <tr><td class="paramname">correct</td><td>The correct output that corresponds to the input we fed in. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The gradient of the surface at the beginning of that backprop step. </dd></dl>

</div>
</div>
<a id="a9a27c95dd469cb1d172e390c901feca9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a27c95dd469cb1d172e390c901feca9">&sect;&nbsp;</a></span>Train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void FFNetwork::Train </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structdata_set.html">dataSet</a>&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>training</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structdata_set.html">dataSet</a>&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>validation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>goal</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">long&#160;</td>
          <td class="paramname"><em>max_epochs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>min_gradient</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Trains the network on the training and validation data provided. The validation data is passed to <a class="el" href="class_f_f_network.html#a4c4f9bbd8d5adbe3813d9b556dbdf312">Evaluate(int,dataSet&lt;double&gt;*)</a>, the training set is used for the actual training.</p>
<p>goal is the cost goal (compared against result from <a class="el" href="class_f_f_network.html#a4c4f9bbd8d5adbe3813d9b556dbdf312">Evaluate(int,dataSet&lt;double&gt;*)</a> max_epochs is the final stopping criterion, generally set to a high value, we rely on the cost or gradient goals more. min_gradient is the smallest gradient we want to have before terminating. Basically, when the gradient (the slope) is smaller than this number, we consider the ball to be at the bottom of the hill.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">training</td><td><a class="el" href="structdata_set.html" title="Holds the data for neural net training, etc. ">dataSet</a> used for training </td></tr>
    <tr><td class="paramname">validation</td><td><a class="el" href="structdata_set.html" title="Holds the data for neural net training, etc. ">dataSet</a> used for validation </td></tr>
    <tr><td class="paramname">goal</td><td>Cost goal - compared against result from <a class="el" href="class_f_f_network.html#a4c4f9bbd8d5adbe3813d9b556dbdf312">Evaluate(int,dataSet&lt;double&gt;*)</a> </td></tr>
    <tr><td class="paramname">max_epochs</td><td>Final stopping criterion - cuts off the training when the number of epochs hits this </td></tr>
    <tr><td class="paramname">min_gradient</td><td>When the gradient is smaller than this number, we consider the ball to be at the bottom of the hill </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Friends And Related Function Documentation</h2>
<a id="aff8be16d3ce26a44e8f057b460d5acfb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff8be16d3ce26a44e8f057b460d5acfb">&sect;&nbsp;</a></span>operator<< <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::ostream&amp; operator&lt;&lt; </td>
          <td>(</td>
          <td class="paramtype">std::ostream &amp;&#160;</td>
          <td class="paramname"><em>out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_f_f_network.html">FFNetwork</a> &amp;&#160;</td>
          <td class="paramname"><em>net</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Prints the network weights and biases to the stdout - careful if you use this with a large network!</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out</td><td></td></tr>
    <tr><td class="paramname">net</td><td></td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd></dd></dl>

</div>
</div>
<a id="abbe40a1420b004e1478d3d900880c346"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abbe40a1420b004e1478d3d900880c346">&sect;&nbsp;</a></span>operator<< <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::ofstream&amp; operator&lt;&lt; </td>
          <td>(</td>
          <td class="paramtype">std::ofstream &amp;&#160;</td>
          <td class="paramname"><em>out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_f_f_network.html">FFNetwork</a> &amp;&#160;</td>
          <td class="paramname"><em>net</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Writes the network details to a file. Ignores the activation functions, etc. because that would be hard.</p>
<p>TODO: Add the network functions to the file (activations, cost, regularization, dropout, derivatives)</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out</td><td>Outgoing file stream </td></tr>
    <tr><td class="paramname">net</td><td>The network to write to a file </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Outgoing file stream </dd></dl>

</div>
</div>
<a id="a75f067d6b9a1d2ba91fa5a5e5b8a8a64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a75f067d6b9a1d2ba91fa5a5e5b8a8a64">&sect;&nbsp;</a></span>operator>></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::ifstream&amp; operator&gt;&gt; </td>
          <td>(</td>
          <td class="paramtype">std::ifstream &amp;&#160;</td>
          <td class="paramname"><em>in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_f_f_network.html">FFNetwork</a> *&#160;</td>
          <td class="paramname"><em>net</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">friend</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Reads from the file outputted by operator&lt;&lt;(std::ofstream&amp;,FFNetwork&amp;). Not guaranteed to work on anything else.</p>
<p>NW - really not working</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">in</td><td>Incoming file stream </td></tr>
    <tr><td class="paramname">filename</td><td>The name of the file that holds the network details </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A network initialized from the weights in the file! </dd></dl>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="aef391b1c34f810e5f43faebf3ea1d9d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef391b1c34f810e5f43faebf3ea1d9d9">&sect;&nbsp;</a></span>backprop</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum { ... }  FFNetwork::backprop</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Chooses the backpropagation algorithm. </p>

</div>
</div>
<a id="a3d7e7add4da8d6e2aa7c9fcd175c50c7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3d7e7add4da8d6e2aa7c9fcd175c50c7">&sect;&nbsp;</a></span>cost</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::VectorXd(* FFNetwork::cost) (Eigen::VectorXd, Eigen::VectorXd)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The cost function - returns a vector that corresponds to the cost per output neuron. </p>

</div>
</div>
<a id="a2d12a1923a6e3faf58df353d9789340c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d12a1923a6e3faf58df353d9789340c">&sect;&nbsp;</a></span>costprime</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Eigen::VectorXd(* FFNetwork::costprime) (Eigen::VectorXd, Eigen::VectorXd, Eigen::VectorXd)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The derivative of the cost function - returns a vector that again corresponds to output neurons. </p>

</div>
</div>
<a id="a975cfb66d3fefd85f96e7715e84a0bf8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a975cfb66d3fefd85f96e7715e84a0bf8">&sect;&nbsp;</a></span>dropout</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;unsigned&gt; FFNetwork::dropout</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Whether each layer is a dropout layer or not. </p>

</div>
</div>
<a id="a8cb7be8b47420fc834e5867dc4640414"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8cb7be8b47420fc834e5867dc4640414">&sect;&nbsp;</a></span>dropout_fn</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double(* FFNetwork::dropout_fn) (double)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Dropout function - currenly only suppored in <a class="el" href="_dropoutand_regularization_8hpp.html">DropoutandRegularization.hpp</a> with Bernoulli. </p>

</div>
</div>
<a id="a5a797019a331d0622cf4fd87df68a59a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a797019a331d0622cf4fd87df68a59a">&sect;&nbsp;</a></span>epsilon</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double FFNetwork::epsilon</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>A small number used in ADADELTA for RMS calculation in the learning rate. </p>

</div>
</div>
<a id="a8634f492cf6aa8c32c7f69eef0daa70e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8634f492cf6aa8c32c7f69eef0daa70e">&sect;&nbsp;</a></span>eta</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double FFNetwork::eta</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Learning rate - used in SGD and MOMSGD only. </p>

</div>
</div>
<a id="a233e8637934edea0a7f94e5eac9d0b9b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a233e8637934edea0a7f94e5eac9d0b9b">&sect;&nbsp;</a></span>gamma</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double FFNetwork::gamma</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Momentum parameter - a scaling parameter for MOMSGD and ADADELTA, around 0.9 is usually good. </p>

</div>
</div>
<a id="afdeb132a945d5df3825f57f069a6d8bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afdeb132a945d5df3825f57f069a6d8bd">&sect;&nbsp;</a></span>lamda</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double FFNetwork::lamda</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Regularization rate - appears in a denominator so a value ~5e3 is recommended and speeds up training. </p>

</div>
</div>
<a id="ac42c2c144ca007bfb21d0b1f38649412"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac42c2c144ca007bfb21d0b1f38649412">&sect;&nbsp;</a></span>layers</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="struct_f_f_layer.html">FFLayer</a>* FFNetwork::layers</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>An array of the layers that make up the network. </p>

</div>
</div>
<a id="a0fb8cf9b00f90297403a015038c2e551"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0fb8cf9b00f90297403a015038c2e551">&sect;&nbsp;</a></span>phi</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double(* FFNetwork::phi) (double)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The activation function. </p>

</div>
</div>
<a id="a60ad55e5abbb5f3a2b017b6f38f17094"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a60ad55e5abbb5f3a2b017b6f38f17094">&sect;&nbsp;</a></span>phiprime</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double(* FFNetwork::phiprime) (double)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Derivative of the activation function. </p>

</div>
</div>
<a id="aded5a5a44a44bd4d2d5971c084912aaa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aded5a5a44a44bd4d2d5971c084912aaa">&sect;&nbsp;</a></span>regularization</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">double(* FFNetwork::regularization) (double)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Regularization function - Identity = L2, Sign = L1, Zero = None. </p>

</div>
</div>
<a id="a280876ec9dc93c5ecb08d7827a4fb83d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a280876ec9dc93c5ecb08d7827a4fb83d">&sect;&nbsp;</a></span>topology</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;unsigned&gt; FFNetwork::topology</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The number of neurons in each layer. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>/Users/Aman/code/NeuralNetworks/include/<a class="el" href="_f_f_network_8hpp_source.html">FFNetwork.hpp</a></li>
<li>/Users/Aman/code/NeuralNetworks/src/<a class="el" href="_f_f_network_8cpp.html">FFNetwork.cpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.12
</small></address>
</body>
</html>
